{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Language Modeling**\n",
        "\n",
        "\n",
        "1.   **Library** (nltk, torch)\n",
        "2.   **Result** (Word prediction using Neural Networks)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JDV1UuYZxYks"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X8P3hPPOxR24"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import re\n",
        "from nltk import FreqDist\n",
        "from nltk.util import ngrams\n",
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downlaod data"
      ],
      "metadata": {
        "id": "q7gaNiADz1p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1qCVYpb67RuzUbyrJ3w-ohtCf-tzZKTal\n",
        "!gdown --id 1dW5SkCYIFbXmNe3xKv4EhrLPDPlXyIDy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JWdJ37PIz2cv",
        "outputId": "2bd50144-1a6c-42c6-97ea-c3302fc29c14"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qCVYpb67RuzUbyrJ3w-ohtCf-tzZKTal\n",
            "To: /content/train.txt\n",
            "100% 9.87M/9.87M [00:00<00:00, 30.9MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dW5SkCYIFbXmNe3xKv4EhrLPDPlXyIDy\n",
            "To: /content/test.txt\n",
            "100% 5.80k/5.80k [00:00<00:00, 23.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess\n",
        "\n",
        "> Ignoring\n",
        "\n",
        "*   extra consecutive spaces\n",
        "*   spaces at the beginning and end of lines"
      ],
      "metadata": {
        "id": "dau1Pbut12vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def file_clear(in_f, out_f):\n",
        "    inputFile = io.open(in_f, mode=\"r\", encoding=\"utf-8\")\n",
        "    outputFile = io.open(out_f, mode=\"w\", encoding=\"utf-8\")\n",
        "\n",
        "    updated=[]\n",
        "    Lines = inputFile.readlines()\n",
        "    for i, line in enumerate(Lines):\n",
        "        newline= re.sub(' +', ' ', line.strip())\n",
        "        if len(line.split()) >2:\n",
        "            updated.append(newline+\"\\n\")\n",
        "        else:\n",
        "            print(line,i)\n",
        "    outputFile.writelines(updated)\n",
        "    print( len(Lines), len(updated))\n",
        "    inputFile.__exit__()\n",
        "    outputFile.__exit__()\n",
        "#updated\n",
        "\n",
        "file_clear('train.txt', 'cleaned_train.txt')\n",
        "file_clear('test.txt', 'cleaned_test.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeBaRN462wiM",
        "outputId": "551635cc-e8de-4452-9c18-17c945a57303"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "بسیارخوری وکامرانی\n",
            " 2438\n",
            "هنگام مکافات\n",
            " 31304\n",
            "حضرت ستارخان\n",
            " 57052\n",
            "سلام چطوری\n",
            " 67800\n",
            "گلبنان ممتحن\n",
            " 74076\n",
            "همدست وهمداستان\n",
            " 78314\n",
            "ای نازنین\n",
            " 96936\n",
            "قصر چلستون\n",
            " 101252\n",
            "بسیار سخن\n",
            " 107340\n",
            "اندر آذربایجان\n",
            " 108670\n",
            "نپذیرند یکی\n",
            " 118562\n",
            "بیشتر کن\n",
            " 140401\n",
            "بیچاره         رعیت\n",
            " 151833\n",
            "اندرگلستان ما\n",
            " 152975\n",
            "ناگاه صبا\n",
            " 159903\n",
            "پرشرر کن\n",
            " 167759\n",
            "همدرد ندارد\n",
            " 175501\n",
            "برملت خوبشتن\n",
            " 184457\n",
            "188894 188876\n",
            "108 108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. Complete the following expressions using the neural language modeling(trigram)\n",
        "\n",
        "\n",
        "1.   چون مشک سیه بود مرا هر دو بنا\n",
        "2.   گر خورد سوگند هم آن\n",
        "3.   زانک نفس آشفته تر گردد از\n",
        "4.   ازین زشت تر در جهان رنگ\n",
        "5.   دوست در خانه و ما گرد\n",
        "6.   شب است و شمع و شراب و\n",
        "\n"
      ],
      "metadata": {
        "id": "Yd4S82wl4Tuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Big Prev Model\n",
        "lm = None\n",
        "\n",
        "#Get Words\n",
        "def compute_freq(inputfile, nu):\n",
        "    textfile = io.open(inputfile, mode=\"r\", encoding=\"utf-8\")\n",
        "    Lines = textfile.readlines()\n",
        "    textfile.__exit__()\n",
        "    ngramfdist = FreqDist()\n",
        "\n",
        "    for i,line in enumerate(Lines):\n",
        "        tokens = line.strip().split(' ')\n",
        "        if len(tokens)>nu:\n",
        "            # ngram_ = ngrams(tokens, nu)\n",
        "            # print(i+1,\" \",line)\n",
        "            ngram_ = ngrams(tokens, nu)\n",
        "            ngramfdist.update(ngram_)\n",
        "    return ngramfdist\n",
        "\n",
        "words = compute_freq(\"cleaned_train.txt\",1)\n",
        "#words_dict = collections.Counter(ngrams)\n",
        "words = [i[0] for i in words]\n",
        "word2int = dict(enumerate(words))\n",
        "word2int = {word: ind for ind, word in word2int.items()}\n",
        "int2word = {value: key for key, value in word2int.items()}\n",
        "int2word.keys()\n",
        "\n",
        "vocab_size= len(int2word)\n",
        "\n",
        "#Get Trigrams\n",
        "def generateSeq(inputfile, nu):\n",
        "    textfile = io.open(inputfile, mode=\"r\", encoding=\"utf-8\")\n",
        "    Lines = textfile.readlines()\n",
        "    textfile.__exit__()\n",
        "    sequences={}\n",
        "    seqIndex=0\n",
        "    for i,line in enumerate(Lines):\n",
        "        tokens = line.strip().split(' ')\n",
        "        if len(tokens)>nu:\n",
        "            ngrams_ = ngrams(tokens, nu)\n",
        "            for tuple_ in ngrams_:\n",
        "                t = list(tuple_)\n",
        "                sequences[seqIndex]= ([word2int[i] for i in t[:-1]], word2int[t[-1]] )\n",
        "                seqIndex = seqIndex+1\n",
        "    return sequences\n",
        "\n",
        "sequences_dict = generateSeq(\"cleaned_train.txt\",3)"
      ],
      "metadata": {
        "id": "rRSaTJpH4iFv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_SIZE = 2\n",
        "EMBEDDING_DIM = 128\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, sequence_dict):\n",
        "        'Initialization'\n",
        "        self.data_dict = sequence_dict\n",
        "        # self.labels = labels\n",
        "        # self.list_IDs = list_IDs\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.data_dict)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        # ID = self.list_IDs[index]\n",
        "\n",
        "        # # Load data and get label\n",
        "        # X = torch.load('data/' + ID + '.pt')\n",
        "        # y = self.labels[ID]\n",
        "        x,y = self.data_dict[index]\n",
        "        return tuple(x), y\n",
        "\n",
        "class NGramLanguageModeler(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(NGramLanguageModeler, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        #embeds = self.embeddings(inputs).view((1, -1))\n",
        "        embeds= torch.cat((self.embeddings(inputs[0]),self.embeddings(inputs[1])),1)\n",
        "        out = F.relu(self.linear1(embeds))\n",
        "        out = self.linear2(out)\n",
        "        log_probs = F.log_softmax(out, dim=1)\n",
        "        return log_probs\n",
        "\n",
        "# Parameters\n",
        "params = {'batch_size': 1024*8,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "max_epochs = 100\n",
        "\n",
        "# Generators\n",
        "training_set = Dataset(sequences_dict)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
        "\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "model = NGramLanguageModeler(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(max_epochs):\n",
        "    total_loss = 0\n",
        "    for context, target in training_generator:\n",
        "\n",
        "        context_idxs = [context[0].to(device), context[1].to(device)]\n",
        "        model.zero_grad()\n",
        "\n",
        "        log_probs = model(context_idxs)\n",
        "\n",
        "        loss = loss_function(log_probs, target.to(device))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(epoch, \" \",total_loss)\n",
        "    losses.append(total_loss)\n",
        "print(losses)  # The loss decreased every iteration over the training data!\n",
        "\n",
        "# To get the embedding of a particular word, e.g. \"beauty\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBSX_eZt6A7r",
        "outputId": "8c4d4dfe-868d-4577-e58a-5be0c2b1fc37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0   970.9450263977051\n",
            "1   835.6389660835266\n",
            "2   812.0403671264648\n",
            "3   792.7543659210205\n",
            "4   774.0541157722473\n",
            "5   754.7730650901794\n",
            "6   734.35977602005\n",
            "7   713.5832123756409\n",
            "8   694.047770023346\n",
            "9   677.6942548751831\n",
            "10   665.0354347229004\n",
            "11   655.4392976760864\n",
            "12   647.4949808120728\n",
            "13   640.7144150733948\n",
            "14   634.7122550010681\n",
            "15   629.3551740646362\n",
            "16   624.405110836029\n",
            "17   619.8325300216675\n",
            "18   615.5947489738464\n",
            "19   611.6133108139038\n",
            "20   607.8593854904175\n",
            "21   604.3041806221008\n",
            "22   600.8442893028259\n",
            "23   597.6631760597229\n",
            "24   594.476667881012\n",
            "25   591.4806203842163\n",
            "26   588.6163301467896\n",
            "27   585.8338694572449\n",
            "28   583.0346217155457\n",
            "29   580.4711384773254\n",
            "30   577.9402618408203\n",
            "31   575.4376316070557\n",
            "32   572.9972620010376\n",
            "33   570.6916518211365\n",
            "34   568.4208574295044\n",
            "35   566.1785836219788\n",
            "36   563.978741645813\n",
            "37   561.8296270370483\n",
            "38   559.7760863304138\n",
            "39   557.705319404602\n",
            "40   555.7080602645874\n",
            "41   553.7185559272766\n",
            "42   551.85515832901\n",
            "43   550.0347504615784\n",
            "44   548.1719274520874\n",
            "45   546.3796949386597\n",
            "46   544.6076259613037\n",
            "47   542.8979163169861\n",
            "48   541.1736516952515\n",
            "49   539.5580973625183\n",
            "50   537.9041624069214\n",
            "51   536.3379426002502\n",
            "52   534.6934323310852\n",
            "53   533.2120785713196\n",
            "54   531.6754989624023\n",
            "55   530.2008409500122\n",
            "56   528.7293453216553\n",
            "57   527.3513307571411\n",
            "58   525.8573637008667\n",
            "59   524.550847530365\n",
            "60   523.1091799736023\n",
            "61   521.8503851890564\n",
            "62   520.4962549209595\n",
            "63   519.2481179237366\n",
            "64   517.995276927948\n",
            "65   516.7279200553894\n",
            "66   515.5106601715088\n",
            "67   514.2963891029358\n",
            "68   513.109296798706\n",
            "69   511.9990406036377\n",
            "70   510.8234658241272\n",
            "71   509.7514591217041\n",
            "72   508.6095724105835\n",
            "73   507.56695652008057\n",
            "74   506.4932246208191\n",
            "75   505.4743571281433\n",
            "76   504.431969165802\n",
            "77   503.39225578308105\n",
            "78   502.36685609817505\n",
            "79   501.44273614883423\n",
            "80   500.4525032043457\n",
            "81   499.5195927619934\n",
            "82   498.5810704231262\n",
            "83   497.6513600349426\n",
            "84   496.7467932701111\n",
            "85   495.8585510253906\n",
            "86   495.0486841201782\n",
            "87   494.16447734832764\n",
            "88   493.253830909729\n",
            "89   492.47046184539795\n",
            "90   491.61893701553345\n",
            "91   490.8161997795105\n",
            "92   490.00068950653076\n",
            "93   489.24247646331787\n",
            "94   488.4588346481323\n",
            "95   487.7097969055176\n",
            "96   486.9484968185425\n",
            "97   486.1900563240051\n",
            "98   485.46163415908813\n",
            "99   484.7201704978943\n",
            "[970.9450263977051, 835.6389660835266, 812.0403671264648, 792.7543659210205, 774.0541157722473, 754.7730650901794, 734.35977602005, 713.5832123756409, 694.047770023346, 677.6942548751831, 665.0354347229004, 655.4392976760864, 647.4949808120728, 640.7144150733948, 634.7122550010681, 629.3551740646362, 624.405110836029, 619.8325300216675, 615.5947489738464, 611.6133108139038, 607.8593854904175, 604.3041806221008, 600.8442893028259, 597.6631760597229, 594.476667881012, 591.4806203842163, 588.6163301467896, 585.8338694572449, 583.0346217155457, 580.4711384773254, 577.9402618408203, 575.4376316070557, 572.9972620010376, 570.6916518211365, 568.4208574295044, 566.1785836219788, 563.978741645813, 561.8296270370483, 559.7760863304138, 557.705319404602, 555.7080602645874, 553.7185559272766, 551.85515832901, 550.0347504615784, 548.1719274520874, 546.3796949386597, 544.6076259613037, 542.8979163169861, 541.1736516952515, 539.5580973625183, 537.9041624069214, 536.3379426002502, 534.6934323310852, 533.2120785713196, 531.6754989624023, 530.2008409500122, 528.7293453216553, 527.3513307571411, 525.8573637008667, 524.550847530365, 523.1091799736023, 521.8503851890564, 520.4962549209595, 519.2481179237366, 517.995276927948, 516.7279200553894, 515.5106601715088, 514.2963891029358, 513.109296798706, 511.9990406036377, 510.8234658241272, 509.7514591217041, 508.6095724105835, 507.56695652008057, 506.4932246208191, 505.4743571281433, 504.431969165802, 503.39225578308105, 502.36685609817505, 501.44273614883423, 500.4525032043457, 499.5195927619934, 498.5810704231262, 497.6513600349426, 496.7467932701111, 495.8585510253906, 495.0486841201782, 494.16447734832764, 493.253830909729, 492.47046184539795, 491.61893701553345, 490.8161997795105, 490.00068950653076, 489.24247646331787, 488.4588346481323, 487.7097969055176, 486.9484968185425, 486.1900563240051, 485.46163415908813, 484.7201704978943]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents_to_comp=[ (\"چون مشک سیه بود مرا هر دو\", 2),\n",
        "                (\"گر خورد سوگند هم آن\", 1),\n",
        "                (\"زانک نفس آشفته تر گردد از\",1),\n",
        "                (\"ازین زشت تر در جهان رنگ\",1),\n",
        "                (\"دوست در خانه و ما گرد\",2),\n",
        "                (\"شب است و شمع و شراب و\",1)\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "for sent, i2 in  sents_to_comp:\n",
        "    for i in range(i2):\n",
        "        sent_words= sent.strip().split()\n",
        "        context = [ torch.tensor([word2int[sent_words[-2]]]).to(device) , torch.tensor([word2int[sent_words[-1]]]).to(device)]\n",
        "        nextWordPreds = model(context)\n",
        "        nextWordID = np.argmax(nextWordPreds.detach().cpu()).item()\n",
        "        nextWord = int2word[nextWordID]\n",
        "        sent = sent + \" \"+ nextWord\n",
        "    print(sent)"
      ],
      "metadata": {
        "id": "dPOr6ubc6qmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3347f942-25f5-48c4-d543-23ea6da450c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "چون مشک سیه بود مرا هر دو را به\n",
            "گر خورد سوگند هم آن را\n",
            "زانک نفس آشفته تر گردد از آن\n",
            "ازین زشت تر در جهان رنگ و\n",
            "دوست در خانه و ما گرد او را\n",
            "شب است و شمع و شراب و کباب\n"
          ]
        }
      ]
    }
  ]
}